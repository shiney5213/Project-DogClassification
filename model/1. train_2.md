train2- accuracy :%

---

#### 1. 개요

- dataset:
  - num_classes : 121
  - train_samples : 23.921
  - val_samples : 4,149
  - test_samples : 7,106

|parameter | setting | ImageGenerator  | setting| test  | result |
| ---------- | -------- | ---------- | -------- | ---------- | ------- |
| base_model| inceptionV3| preprocessing  | inceptionV3 | |  |
| input_size | 299 * 299 | rotation_range | 30 |  | |
| batch_size | 32| width_shift_range | 0.2  |  |  |
| epoch | 15 | height_shift_range  | 0.2  | |  |
| optimizer  | Adam| validation_split  | 0.15  | proper_epoch | |
| leraning_rate | .0001| horizontal_flip  | true  | min_val_loss |  |
|  || interpolation | nearest  | accuracy |  % |

#### 2. 개선 사항 & Model

- InceptionV3 모델 뒤의 layer에 Dropout layer 2개 적용

```
  base_model = InceptionV3(weights='imagenet', include_top = False, input_shape=(299, 299, 3))
          out = base_model.output
          out = Flatten()(out)
          # out = GlobalAveragePooling2D()(out)
          out = Dense(512, activation='relu')(out)
          out = Dropout(0.5)(out)
          out = Dense(512, activation='relu')(out)
          out = Dropout(0.5)(out)
          total_classes = train_generator.num_classes
          predictions = Dense(total_classes, activation='softmax')(out)
          model = Model(inputs=base_model.input, outputs=predictions)
```
- confusion matrix(), precision_recall_fscore_support()부분 수정
```
def confusion_matrix_report(test_genrator, target_names,save_model_path,args):
    steps = test_generator.n // args.BATCH_SIZE 
    Y_pred = model.predict_generator(test_generator)
    y_pred = np.argmax(Y_pred, axis = 1)
    conf_mat = confusion_matrix(test_generator.labels, y_pred)
    conf_df = pd.DataFrame(conf_mat, index = target_names, columns=target_names)
    conf_df.to_csv(save_model_path+'/'+ dir_name + '_confusion_report.csv')

    clf_report =classification_report(true, y_pred, output_dict=True, target_names = target_names)
    clf_df = pd.DataFrame(clf_report).transpose()
    cfl_df.to_csv(save_model_path+'/'+ dir_name + '_classification_report.csv')

def score_df(true, pred, target_names,save_model_path, dir_name):
    clf_rep = metrics.precision_recall_fscore_support(true, pred)
    out_dict = { "precision" :clf_rep[0].round(2)
                ,"recall" : clf_rep[1].round(2)
                ,"f1-score" : clf_rep[2].round(2)
                ,"support" : clf_rep[3] }
    out_df = pd.DataFrame(out_dict, index = target_names)
    avg_tot = (out_df.apply(lambda x: round(x.mean(), 2) if x.name!="support" else  round(x.sum(), 2)).to_frame().T)
    avg_tot.index = ["avg/total"]
    out_df = out_df.append(avg_tot)
    out_df.to_csv(save_model_path+'/'+ dir_name + '_matrix_report.csv')
```



# 수정
#### 3. History

<img src = '../images/1.train.png' width = 100%>

- 중간중간 모델이 저장된 않는 것으로 보아, 이전 epoch보다 성능이 개선되지 않았음을 알 수 있음.
<img src = '../images/1.train_plot.png' width = 100%>
- epoch가 4 이후로는 overfitting이 일어나는 것을 확인할 수 있음.

#### 4. Plan
- overfitting 문제를 해결하기 위해 dropout, Regularization, 모델의 복잡도를 줄이는 방법 등을 적용해봐야겠음.
- code에 Confusion Metric를 그리는 부분의 결과가 이상하게 나옴. 확인 요망

